{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits\n",
    "\n",
    "* make sure to download and unzip the data files (train,test,test_labels) from [this link](https://drive.google.com/file/d/1NuZ5i6EhRopsy8ngwhRZyQWUPHGsSIWM/view?usp=sharing)\n",
    "* it's recommended that you creata a new `conda environment` by running `conda env --name ENV_NAME` replacing the `ENV_NAME` with a name of your choice, and install the `requirments.txt` by executing `pip install -r requirments.txt`\n",
    "* ℹ️ if you don't want to train the model from scratch, download the `pretrained_bilstm_attn` model from [here](https://drive.google.com/file/d/1NsO26I_VTvnqiJFAVA8J7zECZCB8ONI7/view?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explanatory Data Analysis\n",
    "\n",
    "visualize the data and understand the distributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### importing the data from the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "y_true = pd.read_csv('test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### have an idea about the length of the comments strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['number_of_words'] = train_df.comment_text.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>number_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140904</th>\n",
       "      <td>f207ed074493db15</td>\n",
       "      <td>I AM AN LOSER ==== I AM AN LOSER == == I AM AN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>0c7c341727488579</td>\n",
       "      <td>do go fuck off bastard\\nDo Yyou Have a life?\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81295</th>\n",
       "      <td>d970953f86f34327</td>\n",
       "      <td>Take that! \\n\\nIN THE ASS IN THE ASS IN THE AS...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>5fb52a42944da282</td>\n",
       "      <td>What is rong with you u pervert i ahte u just ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136531</th>\n",
       "      <td>da687d5226bff7f3</td>\n",
       "      <td>SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52475</th>\n",
       "      <td>8c5f7911d56a9a58</td>\n",
       "      <td>User_talk:Blackson#Religious_bias</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19815</th>\n",
       "      <td>3452aa44f93b7ee1</td>\n",
       "      <td>(www.ebenefits.va.gov)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130194</th>\n",
       "      <td>b8878c41e3ea8203</td>\n",
       "      <td>hyper_individualist@yahoo.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93586</th>\n",
       "      <td>fa3a30a329e87055</td>\n",
       "      <td>{{unblock|yo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53787</th>\n",
       "      <td>8fb2aaf04e93061a</td>\n",
       "      <td>92.24.199.233|92.24.199.233]]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "140904  f207ed074493db15  I AM AN LOSER ==== I AM AN LOSER == == I AM AN...   \n",
       "4712    0c7c341727488579  do go fuck off bastard\\nDo Yyou Have a life?\\n...   \n",
       "81295   d970953f86f34327  Take that! \\n\\nIN THE ASS IN THE ASS IN THE AS...   \n",
       "35817   5fb52a42944da282  What is rong with you u pervert i ahte u just ...   \n",
       "136531  da687d5226bff7f3  SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D S...   \n",
       "...                  ...                                                ...   \n",
       "52475   8c5f7911d56a9a58                  User_talk:Blackson#Religious_bias   \n",
       "19815   3452aa44f93b7ee1                             (www.ebenefits.va.gov)   \n",
       "130194  b8878c41e3ea8203                      hyper_individualist@yahoo.com   \n",
       "93586   fa3a30a329e87055                                       {{unblock|yo   \n",
       "53787   8fb2aaf04e93061a                      92.24.199.233|92.24.199.233]]   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "140904      1             0        0       0       0              0   \n",
       "4712        1             1        1       1       1              0   \n",
       "81295       1             1        1       0       0              0   \n",
       "35817       1             0        1       0       1              0   \n",
       "136531      1             1        1       0       1              0   \n",
       "...       ...           ...      ...     ...     ...            ...   \n",
       "52475       0             0        0       0       0              0   \n",
       "19815       0             0        0       0       0              0   \n",
       "130194      0             0        0       0       0              0   \n",
       "93586       0             0        0       0       0              0   \n",
       "53787       0             0        0       0       0              0   \n",
       "\n",
       "        number_of_words  \n",
       "140904             1411  \n",
       "4712               1403  \n",
       "81295              1354  \n",
       "35817              1344  \n",
       "136531             1250  \n",
       "...                 ...  \n",
       "52475                 1  \n",
       "19815                 1  \n",
       "130194                1  \n",
       "93586                 1  \n",
       "53787                 1  \n",
       "\n",
       "[159571 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by=['number_of_words'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a lot of comments are of length 1,2 and 3 etc.. these are all columns we can drop from the dataset\n",
    "as they will usually not play an important role in training the model.\n",
    "we will drop comments of length less than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['number_of_words']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152007, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can start cleaning some parts of the comments (removing URLs etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.comment_text.str.contains(r\"^https?:\\/\\/.*[\\r\\n]*\")].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this part was skipped (will be done later due to troubles in the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop the number_of_words column\n",
    "we don't need this column anymore, we will drop it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(labels=['number_of_words'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the column names for the target variables \n",
    "these will be used later to create the train,dev and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_target = train_df.columns[2:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkout the negative labels percentage in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unlabelled comments is  90.04387955817825\n"
     ]
    }
   ],
   "source": [
    "unlabelled_in_all = train_df[(train_df['toxic']!=1) & (train_df['severe_toxic']!=1) & (train_df['obscene']!=1) & \n",
    "                            (train_df['threat']!=1) & (train_df['insult']!=1) & (train_df['identity_hate']!=1)]\n",
    "print('Percentage of unlabelled comments is ', len(unlabelled_in_all)/len(train_df)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if and row doet not have comment_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_comment = train_df[train_df['comment_text'].isnull()]\n",
    "len(no_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, comment_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_comment = test_df[test_df['comment_text'].isnull()]\n",
    "no_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the labels and rows counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in test is 153164\n",
      "Total rows in train is 152007\n",
      "toxic            14234\n",
      "severe_toxic      1447\n",
      "obscene           7760\n",
      "threat             462\n",
      "insult            7268\n",
      "identity_hate     1306\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total rows in test is {}'.format(len(test_df)))\n",
    "print('Total rows in train is {}'.format(len(train_df)))\n",
    "print(train_df[cols_target].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize the labels correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_corr= train_df[cols_target].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(train_df_corr, dtype=np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "heatmap = sns.heatmap(train_df_corr,mask=mask, linewidths=0.1, vmin=0, vmax=1,cmap='BrBG',annot=True,square=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the heatmap above, labels like `Toxic`,`Insult` and `Obscene` are highlt coorelated compared to other labels (i.e. they appear as labels for comments much often than the other comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deep Learning part (BiLSTM with Attention & Binary Relevance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the structure of the model is shown below, a BiLSTM with Attention model was used to implement this task of multi-label classification\n",
    "\n",
    "there are a total of 6 models (one for each label) in the final model, following the binary relevance method to solve multi-label classification\n",
    "<img src=\"./bilstm_attn.jpeg\" width=\"800\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Preprocessing \n",
    " \n",
    "the tokenizer `PreTrainedTokenizerFast` was used to tokenize and transform the sequences into integer sequences which we will use later to index and Embedding Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_set(dataset, max_length=64):\n",
    "    \"\"\"returns input_ids, input_masks, labels for set of data ready in BERT format\"\"\"\n",
    "    global tokenizer\n",
    "    \n",
    "    input_ids = dataset\n",
    "#     for i in tqdm(dataset):\n",
    "#         input_ids.append(camel_case_split(i))\n",
    "    tokenized = tokenizer.batch_encode_plus(input_ids,return_token_type_ids=False, return_attention_mask=False, pad_to_max_length=True,truncation=True, max_length=max_length)[\"input_ids\"]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "hidden_size=64\n",
    "batch_size = 32\n",
    "n_epochs = 4\n",
    "embed_size = 64\n",
    "lr = 0.001\n",
    "model_path = \"BiLSTM_attention_BiRel.pt\"\n",
    "use_gpu = True\n",
    "dev_size = int(train_df.shape[0] * 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking if there exists a GPU on the machine to use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device config\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"a Single Attention Layer\"\"\"\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.feature_dim = feature_dim\n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "    \n",
    "    def forward(self, x, step_dim, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1), torch.unsqueeze(a, -1)\n",
    "\n",
    "\n",
    "class BiLSTMWithAttention(nn.Module):\n",
    "    \"\"\"the BiLSTM model refer to the image above to understand the structure of the model\"\"\"\n",
    "    def __init__(self,hidden_size,embed_size,max_features,num_classes,max_length):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.lstm1 = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.lstm_attention = Attention(hidden_size * 2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_size*6, hidden_size*6)\n",
    "        self.linear2 = nn.Linear(hidden_size*6, hidden_size*6)\n",
    "        \n",
    "        self.linear_out = nn.Linear(hidden_size*6, 1)\n",
    "        self.linear_aux_out = nn.Linear(hidden_size*6, num_classes)\n",
    "    \n",
    "    def forward(self, x, step_len):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        #Attention layer\n",
    "        h_lstm_atten, weights = self.lstm_attention(h_lstm2, max_length)\n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_lstm2, 1)\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(h_lstm2, 1)\n",
    "        h_conc = torch.cat((h_lstm_atten, max_pool, avg_pool), 1)\n",
    "        h_conc_linear1 = F.relu(self.linear1(h_conc))\n",
    "        h_conc_linear2 = F.relu(self.linear2(h_conc))\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "#         out = torch.cat([result, aux_result], 1)\n",
    "#         print(f\"out : {out.shape}\")\n",
    "#         return out, weights\n",
    "        return aux_result, weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training Loop\n",
    "\n",
    "* mini batching was used to increase the performance\n",
    "* because this is a multi-label classification problem, a proper criterion needed to be chosen, in this case it was BCEWithLogitsLoss (which is the BCE with sigmoid implemented internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(models, loss_fn, lr=0.001, batch_size=32, n_epochs=10,max_length=64):\n",
    "    for col in cols_target:\n",
    "        models[col]['param_lrs'] = [{'params': param, 'lr': lr} for param in models[col]['model'].parameters()]\n",
    "        models[col]['optimizer'] = torch.optim.Adam(models[col]['param_lrs'], lr=lr)\n",
    "        models[col]['training_loss'] = []\n",
    "        models[col]['validation_loss'] = []\n",
    "\n",
    "    \n",
    "    \n",
    "    for model_index,target_label in enumerate(cols_target):\n",
    "        print(\"=\"*50)\n",
    "        print(f\"training {target_label} model....\")\n",
    "        models[target_label]['model'].to(device)\n",
    "        \n",
    "        best_loss = float(\"inf\")\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            models[target_label]['model'].train()\n",
    "            avg_loss = 0\n",
    "\n",
    "            for data in tqdm(train_dataloader, disable=False):\n",
    "                x_batch = data[:-1]\n",
    "                y_batch = data[-1][:,model_index].unsqueeze(1)\n",
    "\n",
    "                y_pred, _ = models[target_label]['model'](*x_batch, max_length)\n",
    "                \n",
    "                loss = nn.BCEWithLogitsLoss()(y_pred,y_batch)\n",
    "                models[target_label]['optimizer'].zero_grad()\n",
    "                loss.backward()\n",
    "                models[target_label]['optimizer'].step()\n",
    "                avg_loss += loss.item() / len(train_dataloader)\n",
    "\n",
    "            models[target_label]['training_loss'].append(avg_loss)\n",
    "            models[target_label]['model'].eval()\n",
    "            \n",
    "            print(f'... Validating ... ')\n",
    "            \n",
    "            avg_val_loss = 0\n",
    "            \n",
    "            for val_data in tqdm(dev_dataloader, disable=False):\n",
    "                x_batch = val_data[:-1]\n",
    "                y_batch = val_data[-1][:,model_index].unsqueeze(1)\n",
    "\n",
    "                y_pred, _ = models[target_label]['model'](*x_batch, max_length)\n",
    "\n",
    "                val_loss = nn.BCEWithLogitsLoss()(y_pred, y_batch)\n",
    "                avg_val_loss += val_loss.item() / len(dev_dataloader)\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            models[target_label]['validation_loss'].append(avg_val_loss)\n",
    "            \n",
    "            if avg_val_loss < best_loss:\n",
    "                print('saving the best model so far')\n",
    "                best_loss = avg_val_loss\n",
    "                torch.save(models[target_label]['model'].state_dict(), target_label+'_model.pt')\n",
    "            print(f'Epoch {epoch + 1}/{n_epochs}\\t training_loss={avg_loss:.4f} \\t validation_loss={avg_val_loss: 4f} \\t time={elapsed_time:.2f}s')\n",
    "    \n",
    "    models.clear()\n",
    "    \n",
    "    models = {\n",
    "        'toxic':{},\n",
    "        'severe_toxic':{},\n",
    "        'obscene':{},\n",
    "        'threat':{},\n",
    "        'insult':{},\n",
    "        'identity_hate':{}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    print(\"loading best models .... \")\n",
    "    for target_label in cols_target:\n",
    "        # load each best model into its corresponding dict key\n",
    "        models[target_label]['model'] = BiLSTMWithAttention(hidden_size=hidden_size,\n",
    "                        embed_size=embed_size,\n",
    "                        max_features=tokenizer.vocab_size,\n",
    "                        num_classes=1,\n",
    "                        max_length=max_length)\n",
    "        models[target_label]['model'].load_state_dict(torch.load(target_label+'_model.pt'))\n",
    "        os.remove(target_label+'_model.pt')\n",
    "    \n",
    "    print(\"saving best models into a single file .... \")\n",
    "    # saving all models in a single model file\n",
    "    torch.save({\n",
    "            'toxic': models['toxic']['model'].state_dict(),\n",
    "            'severe_toxic': models['severe_toxic']['model'].state_dict(),\n",
    "            'obscene': models['obscene']['model'].state_dict(),\n",
    "            'threat': models['threat']['model'].state_dict(),\n",
    "            'insult': models['insult']['model'].state_dict(),\n",
    "            'identity_hate': models['identity_hate']['model'].state_dict(),\n",
    "            }, model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The evaulating/testing part\n",
    "\n",
    "* each time a mini batch is run through the model and the corresponding weigts are saved and column-summed to get the count of True Positive labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(models):\n",
    "    for model_index,target_label in enumerate(cols_target):\n",
    "        \n",
    "        print(\"=\"*40)\n",
    "        print(f\"evaluating {target_label} model .... \")\n",
    "        \n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        \n",
    "        models[col]['model'].eval()\n",
    "        with torch.no_grad():\n",
    "            for tst_data in tqdm(test_dataloader, disable=False):\n",
    "                x_batch = tst_data[:-1]\n",
    "                y_batch_labels = tst_data[-1][:,model_index].detach().cpu().numpy()\n",
    "\n",
    "                y_pred, _ = models[col]['model'](*x_batch, max_length)\n",
    "\n",
    "                y_pred_labels = (torch.sigmoid(y_pred).detach().cpu().numpy() > 0.5)\n",
    "\n",
    "                y_preds.extend(y_pred_labels.squeeze(1))\n",
    "                y_trues.extend(y_batch_labels)\n",
    "        \n",
    "        print(confusion_matrix(y_true=y_trues,y_pred=y_preds))\n",
    "        print(classification_report(y_trues,y_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the datasets\n",
    "\n",
    "* a portion specified by dev_size is taken from the training dataframe to be used as a dev set, this would help us after each epoch to see how our model is doing (i.e. generalizing the model)\n",
    "* each data is tokenized and turned into sequence ids and converted into torch.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_cpy = train_df[dev_size:]\n",
    "dev_df_cpy = train_df[:dev_size]\n",
    "test_df_cpy = test_df\n",
    "y_true_cpy = y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madbulattif18/anaconda3/envs/myenv/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing training data...\n",
      "preprocessing test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madbulattif18/anaconda3/envs/myenv/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "print(\"preprocessing training data...\")\n",
    "X_train = prepare_set(train_df_cpy['comment_text'].values.tolist())\n",
    "\n",
    "print(\"preprocessing training data...\")\n",
    "X_dev = prepare_set(dev_df_cpy['comment_text'].values.tolist())\n",
    "\n",
    "print(\"preprocessing test data...\")\n",
    "test_df = pd.merge(test_df_cpy,y_true_cpy,on='id')\n",
    "# -1 labels mean that those lines were not used for the scoring \n",
    "test_df = test_df[test_df[\"toxic\"] >= 0]\n",
    "\n",
    "X_test = prepare_set(test_df['comment_text'].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df_cpy[cols_target].values\n",
    "y_dev = dev_df_cpy[cols_target].values\n",
    "y_test = test_df[cols_target].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_torch = torch.tensor(X_train, dtype=torch.long).to(device)\n",
    "x_dev_torch = torch.tensor(X_dev, dtype=torch.long).to(device)\n",
    "x_test_torch = torch.tensor(X_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_torch = torch.tensor(np.hstack([y_train, y_aux_train]), dtype=torch.float32).to(device)\n",
    "y_train_torch = torch.tensor(y_train,dtype=torch.float).to(device)\n",
    "y_dev_torch = torch.tensor(y_dev, dtype=torch.float).to(device)\n",
    "# y_val_torch = torch.tensor(np.hstack([y_val, y_aux_val]), dtype=torch.float32).to(device)\n",
    "y_test_torch = torch.tensor(y_test,dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for training set\n",
    "train_data = TensorDataset(x_train_torch, y_train_torch)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for dev set\n",
    "dev_data = TensorDataset(x_dev_torch, y_dev_torch)\n",
    "dev_sampler = RandomSampler(dev_data)\n",
    "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for dev set.\n",
    "test_data = TensorDataset(x_test_torch, y_test_torch)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'toxic':{},\n",
    "    'severe_toxic':{},\n",
    "    'obscene':{},\n",
    "    'threat':{},\n",
    "    'insult':{},\n",
    "    'identity_hate':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_target:\n",
    "    models[col]['model'] = BiLSTMWithAttention(hidden_size=hidden_size,\n",
    "                            embed_size=embed_size,\n",
    "                            max_features=tokenizer.vocab_size,\n",
    "                            num_classes=1,\n",
    "                            max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': {'model': BiLSTMWithAttention(\n",
       "    (embedding): Embedding(30522, 64)\n",
       "    (lstm1): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm_attention): Attention()\n",
       "    (linear1): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "    (linear_aux_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "  )},\n",
       " 'severe_toxic': {'model': BiLSTMWithAttention(\n",
       "    (embedding): Embedding(30522, 64)\n",
       "    (lstm1): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm_attention): Attention()\n",
       "    (linear1): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "    (linear_aux_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "  )},\n",
       " 'obscene': {'model': BiLSTMWithAttention(\n",
       "    (embedding): Embedding(30522, 64)\n",
       "    (lstm1): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm_attention): Attention()\n",
       "    (linear1): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "    (linear_aux_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "  )},\n",
       " 'threat': {'model': BiLSTMWithAttention(\n",
       "    (embedding): Embedding(30522, 64)\n",
       "    (lstm1): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm_attention): Attention()\n",
       "    (linear1): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "    (linear_aux_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "  )},\n",
       " 'insult': {'model': BiLSTMWithAttention(\n",
       "    (embedding): Embedding(30522, 64)\n",
       "    (lstm1): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm_attention): Attention()\n",
       "    (linear1): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "    (linear_aux_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "  )},\n",
       " 'identity_hate': {'model': BiLSTMWithAttention(\n",
       "    (embedding): Embedding(30522, 64)\n",
       "    (lstm1): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "    (lstm_attention): Attention()\n",
       "    (linear1): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (linear_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "    (linear_aux_out): Linear(in_features=384, out_features=1, bias=True)\n",
       "  )}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "if you want to train the model from scratch, umcomment the next cell, otherwise you might opt to load the pretrained model (link shown in the prerequsits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models returns the trained models\n",
    "#train_model(models=models,loss_fn=None,lr=lr,batch_size=batch_size,n_epochs=n_epochs,max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the pretrained models\n",
    "make sure that you have downloaded the model, and put it in the same directory as the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the single file that contains the 6 models\n",
    "models_single_file = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting each model into its corresponding key in the dictionary, and load them into the GPU\n",
    "for col in cols_target:\n",
    "    models[col]['model'].load_state_dict(models_single_file[col])\n",
    "    models[col]['model'].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating each model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:00<00:17, 113.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "evaluating toxic model .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 216.58it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57885     3]\n",
      " [ 5977   113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95     57888\n",
      "         1.0       0.97      0.02      0.04      6090\n",
      "\n",
      "    accuracy                           0.91     63978\n",
      "   macro avg       0.94      0.51      0.49     63978\n",
      "weighted avg       0.91      0.91      0.86     63978\n",
      "\n",
      "========================================\n",
      "evaluating severe_toxic model .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 221.56it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63532    79]\n",
      " [  330    37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00     63611\n",
      "         1.0       0.32      0.10      0.15       367\n",
      "\n",
      "    accuracy                           0.99     63978\n",
      "   macro avg       0.66      0.55      0.58     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "========================================\n",
      "evaluating obscene model .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 221.57it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60264    23]\n",
      " [ 3598    93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97     60287\n",
      "         1.0       0.80      0.03      0.05      3691\n",
      "\n",
      "    accuracy                           0.94     63978\n",
      "   macro avg       0.87      0.51      0.51     63978\n",
      "weighted avg       0.94      0.94      0.92     63978\n",
      "\n",
      "========================================\n",
      "evaluating threat model .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 221.57it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63658   109]\n",
      " [  204     7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     63767\n",
      "         1.0       0.06      0.03      0.04       211\n",
      "\n",
      "    accuracy                           1.00     63978\n",
      "   macro avg       0.53      0.52      0.52     63978\n",
      "weighted avg       0.99      1.00      0.99     63978\n",
      "\n",
      "========================================\n",
      "evaluating insult model .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 221.54it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60534    17]\n",
      " [ 3328    99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     60551\n",
      "         1.0       0.85      0.03      0.06      3427\n",
      "\n",
      "    accuracy                           0.95     63978\n",
      "   macro avg       0.90      0.51      0.51     63978\n",
      "weighted avg       0.94      0.95      0.92     63978\n",
      "\n",
      "========================================\n",
      "evaluating identity_hate model .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 221.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63255    11]\n",
      " [  607   105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00     63266\n",
      "         1.0       0.91      0.15      0.25       712\n",
      "\n",
      "    accuracy                           0.99     63978\n",
      "   macro avg       0.95      0.57      0.62     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks \n",
    "\n",
    "* from the classification reports above we can see that our models have ~100% recall for the negative class, this is due to the negative class unbalance.\n",
    "* On the other hand, the model has low recall for the positive class for each label\n",
    "* although the model achieves good accuracy in predicting each label in the dataset, other hpyerparameter and modifications might be required to make it better. (adding drop, decreasing the complexity etc..)\n",
    "* The attention layer fairly good to detect the part the might trigger a label.\n",
    "\n",
    "* ⚠️ the dimenions in the figure doesn't match the trained model below, however the structure is the same, it was changed because the dimensions in the figure below caused the model to overfit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_color_shades = {\n",
    "    'toxic':[(176, 58, 46),(203, 67, 53),(231, 76, 60),(236, 112, 99),(241, 148, 138),(245, 183, 177),(250, 219, 216),(253, 237, 236)],\n",
    "    'severe_toxic':[(118, 68, 138) , (136, 78, 160) , (155, 89, 182) , (175, 122, 197) ,(195, 155, 211) ,(215, 189, 226) ,(235, 222, 240) ,(245, 238, 248)],\n",
    "    'obscene':[(31, 97, 141), (36, 113, 163) ,(41, 128, 185), (84, 153, 199),(127, 179, 213),(169, 204, 227),(212, 230, 241),(234, 242, 248)],\n",
    "    'threat':[(20, 143, 119) , (23, 165, 137) , (26, 188, 156) , (72, 201, 176),( 118, 215, 196),(163, 228, 215),(209, 242, 235),(232, 248, 245)],\n",
    "    'insult':[(183, 149, 11), (212, 172, 13) , (241, 196, 15), (244, 208, 63), (247, 220, 111), (249, 231, 159),(252, 243, 207),(254, 249, 231)],\n",
    "    'identity_hate':[(113, 125, 126),(131, 145, 146),(149, 165, 166),(170, 183, 184),(191, 201, 202),(213, 219, 219),(234, 237, 237),(244, 246, 246)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_escape(rgb_tuple, background=False):\n",
    "    return '\\033[{};2;{};{};{}m'.format(48 if background else 38, rgb_tuple[0], rgb_tuple[1], rgb_tuple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorText(token,rgb_tuple):\n",
    "    return get_color_escape((0, 0, 0)) + get_color_escape(rgb_tuple, True)+ token + '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_input():\n",
    "    while True:\n",
    "        str_input = input(\"Enter a String:\")\n",
    "        if str_input == 'quit':\n",
    "            break\n",
    "        input_ids = prepare_set([str_input])\n",
    "        with torch.no_grad():\n",
    "            for target_label in cols_target:\n",
    "                single_x = torch.tensor(input_ids,dtype=torch.long).to(device)\n",
    "                single_y, attention_w = models[target_label]['model'](single_x,max_length)\n",
    "\n",
    "                ys = torch.sigmoid(single_y).detach().cpu().numpy().flatten()\n",
    "                attention_w = attention_w.detach().cpu().numpy().flatten()\n",
    "                \n",
    "                if(ys[0]>0.2):\n",
    "                    decoded_str = tokenizer.decode(*input_ids).split()\n",
    "                    attention_ids = [decoded_str.index(w) for w in decoded_str if (w != \"[CLS]\" and w != \"[SEP]\" and w != \"[PAD]\")]\n",
    "\n",
    "                    highlighted_str = []\n",
    "\n",
    "                    max_atten = max(attention_w[attention_ids])\n",
    "                    min_atten = min(attention_w[attention_ids])\n",
    "\n",
    "\n",
    "\n",
    "                    for _id in attention_ids:\n",
    "\n",
    "                        color_shade = math.floor(((max_atten-attention_w[_id])/(max_atten-min_atten))*7)\n",
    "                        token_rgb_color = rgb_color_shades[target_label][color_shade]\n",
    "\n",
    "                        highlighted_str.append(colorText(decoded_str[_id],token_rgb_color))\n",
    "\n",
    "                    print(f\"label {target_label} : {ys[0]*100:.2f}%\")\n",
    "                    print(f\"String after attention and multi-label classification: {' '.join(highlighted_str)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a String:he's a racist dog and he should kill himself\n",
      "label toxic : 98.79%\n",
      "String after attention and multi-label classification: \u001b[38;2;0;0;0m\u001b[48;2;245;183;177mhe's\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;241;148;138ma\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;231;76;60mracist\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;203;67;53mdog\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;176;58;46mand\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;176;58;46mhe\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;236;112;99mshould\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;253;237;236mkill\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;241;148;138mhimself\u001b[0m\n",
      "label threat : 24.80%\n",
      "String after attention and multi-label classification: \u001b[38;2;0;0;0m\u001b[48;2;209;242;235mhe's\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;209;242;235ma\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;209;242;235mracist\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;209;242;235mdog\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;232;248;245mand\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;163;228;215mhe\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;118;215;196mshould\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;20;143;119mkill\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;20;143;119mhimself\u001b[0m\n",
      "label insult : 23.55%\n",
      "String after attention and multi-label classification: \u001b[38;2;0;0;0m\u001b[48;2;247;220;111mhe's\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;247;220;111ma\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;244;208;63mracist\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;241;196;15mdog\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;183;149;11mand\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;241;196;15mhe\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;252;243;207mshould\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;252;243;207mkill\u001b[0m \u001b[38;2;0;0;0m\u001b[48;2;254;249;231mhimself\u001b[0m\n",
      "Enter a String:quit\n"
     ]
    }
   ],
   "source": [
    "predict_user_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
